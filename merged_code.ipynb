{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating to Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gautam.v/Codes/AIISC/data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_folder = '/Users/gautam.v/Codes/AIISC/data'\n",
    "%cd $data_folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade diffusers transformers accelerate mediapy triton scipy ftfy spacy==3.5.0\n",
    "%pip install -q xformers==0.0.16rc425\n",
    "%pip install daam==0.0.11"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import PNDMScheduler, DDIMScheduler, LMSDiscreteScheduler, EulerDiscreteScheduler, DPMSolverMultistepScheduler\n",
    "import mediapy as media\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import daam\n",
    "import time\n",
    "from torch import autocast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_model_id = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "# diffusion_model_id = \"stabilityai/stable-diffusion-2-1\"\n",
    "# diffusion_model_id = \"dreamlike-art/dreamlike-photoreal-2.0\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = None\n",
    "# scheduler = PNDMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "# scheduler = DDIMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "# scheduler = LMSDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "# scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "# scheduler = DPMSolverMultistepScheduler.from_pretrained(model_id, subfolder=\"scheduler\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if diffusion_model_id.startswith(\"stabilityai/\"):\n",
    "  model_revision = \"fp16\"\n",
    "else:\n",
    "  model_revision = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Image Size Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if diffusion_model_id.endswith('-base'):\n",
    "  image_length = 512\n",
    "else:\n",
    "  image_length = 768"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'all_claims.xlsx' # Replace with the actual path to the data\n",
    "df = pd.read_excel(data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_scores(claim, lst,processor,model):\n",
    "  inputs = processor(text=claim, images=lst, return_tensors=\"pt\", padding=True)\n",
    "  outputs = model(**inputs)\n",
    "  logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "  best_image = max(logits_per_image)\n",
    "  arg_max = torch.argmax(logits_per_image)\n",
    "  return logits_per_image, best_image, arg_max"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxillary and IO Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(filename, intval):\n",
    "    with open(filename, 'w') as fp:\n",
    "        fp.write(str(intval))\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename) as fp:\n",
    "        return fp.read()\n",
    "    \n",
    "def set_seed(seed):\n",
    "  gen = torch.Generator(device=device)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  return gen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation for N Claims"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(diffusion_model_id)\n",
    "pipe = pipe.to(device)\n",
    "# prompt = 'Deepika Padukone buying liquor in Mumbai' # provide the prompt , iterate over the list of claims in fever and run the loop\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "# N is the number of claims\n",
    "N = 5\n",
    "# num_images is the number of images to be generated per claim\n",
    "num_images = 8\n",
    "# Base path of where the images and logs will be stored\n",
    "base_path = \"/Users/gautam.v/Codes/DeHate/generated_images\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decide if Negative Prompts Need to be Omitted or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_safety = False # can be changed to True when and if needed\n",
    "if remove_safety:\n",
    "  negative_prompt = None\n",
    "  pipe.safety_checker = None\n",
    "else:\n",
    "  negative_prompt = \"nude, naked\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for claim_idx in range(N):\n",
    "  assert \"claim\" in df.columns, \"The column name should be claim\"\n",
    "  claim_folder = os.path.join(base_path, f\"Claim_idx_{claim_idx}\")\n",
    "  if not os.path.exists(claim_folder):\n",
    "    os.makedirs(claim_folder)\n",
    "  claim_text = df.claim[claim_idx]\n",
    "  images_list = []\n",
    "  seed_time = int(time.time())\n",
    "  gen = set_seed(seed_time)  # for reproducibility\n",
    "  with daam.trace(pipe) as tc:\n",
    "    with autocast(device):\n",
    "      for image_idx in range(1,num_images+1):\n",
    "        image = pipe(\n",
    "        claim_text,\n",
    "        height = image_length,\n",
    "        width = image_length,\n",
    "        num_inference_steps = 25, # this is just for trial. change to >=500 for good results\n",
    "        guidance_scale = 9,\n",
    "        negative_prompt = negative_prompt,\n",
    "        generator = gen\n",
    "        )['images'][0]\n",
    "        images_list.append(image)\n",
    "        image_name = f\"Image_no_{image_idx}.png\"\n",
    "        image_path = os.path.join(claim_folder, image_name)\n",
    "        image.save(image_path)\n",
    "        daam_path = os.path.join(claim_folder, f\"daam_{image_idx}\")\n",
    "        exp = tc.to_experiment(daam_path)\n",
    "        exp.save()  # experiment-dir now contains all the data and heat maps\n",
    "  logits_per_image, best_image, arg_max = get_clip_scores(claim_text, images_list,processor,model)\n",
    "  logging_file_name = os.path.join(claim_folder, \"best_image_log.txt\")\n",
    "  logging_text = f\"All CLIP Scores: {logits_per_image} Best Image: image_{int(arg_max)} with CLIP score of {best_image}\"\n",
    "  write_file(logging_file_name,logging_text)\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
